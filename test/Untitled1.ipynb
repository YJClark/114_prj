{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhhh1B0x6Vik8wwMWehzbo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install docplex\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYQzcurDx2OM",
        "outputId": "92081e29-238d-4432-938a-4fc87ed8eacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docplex\n",
            "  Downloading docplex-2.27.239.tar.gz (635 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.6/635.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from docplex) (1.16.0)\n",
            "Building wheels for collected packages: docplex\n",
            "  Building wheel for docplex (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docplex: filename=docplex-2.27.239-py3-none-any.whl size=674503 sha256=3ba4b5343ff0a27083cb4d10892e98a65042424f99f85e30dc0283cb22fdb211\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/7c/db/cef9425e1cedbf45621545097eaaeed5efe07005bd8229dd74\n",
            "Successfully built docplex\n",
            "Installing collected packages: docplex\n",
            "Successfully installed docplex-2.27.239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cplex\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUildK5DyRz_",
        "outputId": "942d4fea-1b78-4b62-d29d-2d039e88d6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cplex\n",
            "  Downloading cplex-22.1.1.2-cp310-cp310-manylinux1_x86_64.whl (44.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cplex\n",
            "Successfully installed cplex-22.1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "#Code for DRL policy iteration algorithm\n",
        "\n",
        "# Set up environment\n",
        "import argparse\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import datetime\n",
        "from time import time\n",
        "from scipy.stats import norm\n",
        "from math import ceil, floor\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "print(\"Moment 1: imported standard Python libs. Now ML Libs...\")\n",
        "# import the necessary packages\n",
        "import csv\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from docplex.mp.solution import SolveSolution\n",
        "from docplex.mp.model import Model\n",
        "\n",
        "import sys\n",
        "\n",
        "from cplex.callbacks import HeuristicCallback, UserCutCallback, LazyConstraintCallback\n",
        "\n",
        "from docplex.mp.callbacks.cb_mixin import *\n",
        "\n",
        "\n",
        "print(\"Moment 2: imported ML and CPLEX Python libs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGcBh5U0xzDs",
        "outputId": "1b6036d5-6827-4338-d520-5a2350ce4438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moment 1: imported standard Python libs. Now ML Libs...\n",
            "Moment 2: imported ML and CPLEX Python libs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fW89MotVxqPS",
        "outputId": "6fbbea8e-ea83-468c-b3e7-73cc7d6bcd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main Program started\n",
            "Read Instance Data\n",
            "Instance  70   has been loaded\n",
            "Going to Generate Scenarios for training...\n",
            "All Scenarios for Policy Evaluation and Simulation Generated...\n",
            "Initialize NN\n",
            "Initiating Value Function evaluation for algo  DRL_REW1  Iter=  0\n",
            "Value Function table mount has ended\n",
            "[INFO] training network...\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: loss improved from inf to 12450617.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 12450617.0000 - 827ms/epoch - 3ms/step\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12823795.0000 - 334ms/epoch - 1ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12782062.0000 - 560ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12798962.0000 - 467ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12786495.0000 - 490ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12774051.0000 - 528ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12761611.0000 - 557ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12749188.0000 - 318ms/epoch - 1ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12736784.0000 - 330ms/epoch - 1ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12724377.0000 - 334ms/epoch - 1ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12711995.0000 - 332ms/epoch - 1ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12699619.0000 - 319ms/epoch - 1ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12687259.0000 - 346ms/epoch - 1ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12674906.0000 - 330ms/epoch - 1ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12662579.0000 - 327ms/epoch - 1ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12650247.0000 - 348ms/epoch - 1ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12637934.0000 - 327ms/epoch - 1ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12625644.0000 - 651ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12613349.0000 - 609ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12601074.0000 - 719ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12588806.0000 - 821ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12576553.0000 - 743ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12564314.0000 - 600ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12552088.0000 - 396ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12539870.0000 - 548ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12527672.0000 - 482ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12515481.0000 - 522ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12503300.0000 - 519ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 29: loss did not improve from 12450617.00000\n",
            "248/248 - 1s - loss: 12491140.0000 - 515ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12478982.0000 - 397ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 31: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12466839.0000 - 340ms/epoch - 1ms/step\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 32: loss did not improve from 12450617.00000\n",
            "248/248 - 0s - loss: 12454706.0000 - 322ms/epoch - 1ms/step\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 33: loss improved from 12450617.00000 to 12442587.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12442587.0000 - 373ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 34: loss improved from 12442587.00000 to 12430483.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12430483.0000 - 344ms/epoch - 1ms/step\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: loss improved from 12430483.00000 to 12418385.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12418385.0000 - 336ms/epoch - 1ms/step\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 36: loss improved from 12418385.00000 to 12406305.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12406305.0000 - 334ms/epoch - 1ms/step\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 37: loss improved from 12406305.00000 to 12394237.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12394237.0000 - 340ms/epoch - 1ms/step\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 38: loss improved from 12394237.00000 to 12382173.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12382173.0000 - 331ms/epoch - 1ms/step\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 39: loss improved from 12382173.00000 to 12370129.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12370129.0000 - 335ms/epoch - 1ms/step\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: loss improved from 12370129.00000 to 12358092.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12358092.0000 - 336ms/epoch - 1ms/step\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 41: loss improved from 12358092.00000 to 12346070.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12346070.0000 - 325ms/epoch - 1ms/step\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 42: loss improved from 12346070.00000 to 12334061.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12334061.0000 - 433ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 43: loss improved from 12334061.00000 to 12322059.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12322059.0000 - 467ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 44: loss improved from 12322059.00000 to 12310069.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12310069.0000 - 345ms/epoch - 1ms/step\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: loss improved from 12310069.00000 to 12298098.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12298098.0000 - 491ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 46: loss improved from 12298098.00000 to 12286135.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12286135.0000 - 340ms/epoch - 1ms/step\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 47: loss improved from 12286135.00000 to 12274179.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12274179.0000 - 353ms/epoch - 1ms/step\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 48: loss improved from 12274179.00000 to 12262245.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12262245.0000 - 341ms/epoch - 1ms/step\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 49: loss improved from 12262245.00000 to 12250315.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12250315.0000 - 392ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: loss improved from 12250315.00000 to 12238398.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 12238398.0000 - 510ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 51: loss improved from 12238398.00000 to 12226493.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 12226493.0000 - 503ms/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 52: loss improved from 12226493.00000 to 12214600.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 12214600.0000 - 520ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 53: loss improved from 12214600.00000 to 12202721.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 12202721.0000 - 510ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 54: loss improved from 12202721.00000 to 12190858.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12190858.0000 - 402ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: loss improved from 12190858.00000 to 12178992.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12178992.0000 - 335ms/epoch - 1ms/step\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 56: loss improved from 12178992.00000 to 12167149.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12167149.0000 - 346ms/epoch - 1ms/step\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 57: loss improved from 12167149.00000 to 12155315.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12155315.0000 - 329ms/epoch - 1ms/step\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 58: loss improved from 12155315.00000 to 12143498.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12143498.0000 - 342ms/epoch - 1ms/step\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 59: loss improved from 12143498.00000 to 12131688.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12131688.0000 - 335ms/epoch - 1ms/step\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 60: loss improved from 12131688.00000 to 12119890.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12119890.0000 - 334ms/epoch - 1ms/step\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 61: loss improved from 12119890.00000 to 12108107.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12108107.0000 - 331ms/epoch - 1ms/step\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 62: loss improved from 12108107.00000 to 12096330.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12096330.0000 - 324ms/epoch - 1ms/step\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 63: loss improved from 12096330.00000 to 12084564.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12084564.0000 - 337ms/epoch - 1ms/step\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 64: loss improved from 12084564.00000 to 12072817.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12072817.0000 - 328ms/epoch - 1ms/step\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 65: loss improved from 12072817.00000 to 12061075.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12061075.0000 - 354ms/epoch - 1ms/step\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 66: loss improved from 12061075.00000 to 12049343.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12049343.0000 - 328ms/epoch - 1ms/step\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 67: loss improved from 12049343.00000 to 12037626.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12037626.0000 - 347ms/epoch - 1ms/step\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 68: loss improved from 12037626.00000 to 12025925.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12025925.0000 - 330ms/epoch - 1ms/step\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 69: loss improved from 12025925.00000 to 12014234.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12014234.0000 - 347ms/epoch - 1ms/step\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 70: loss improved from 12014234.00000 to 12002544.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 12002544.0000 - 341ms/epoch - 1ms/step\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 71: loss improved from 12002544.00000 to 11990874.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11990874.0000 - 330ms/epoch - 1ms/step\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 72: loss improved from 11990874.00000 to 11979216.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11979216.0000 - 340ms/epoch - 1ms/step\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 73: loss improved from 11979216.00000 to 11967570.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11967570.0000 - 335ms/epoch - 1ms/step\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 74: loss improved from 11967570.00000 to 11955931.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11955931.0000 - 342ms/epoch - 1ms/step\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 75: loss improved from 11955931.00000 to 11944312.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11944312.0000 - 374ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 76: loss improved from 11944312.00000 to 11932698.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 11932698.0000 - 508ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 77: loss improved from 11932698.00000 to 11921091.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 11921091.0000 - 535ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 78: loss improved from 11921091.00000 to 11909506.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 11909506.0000 - 508ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 79: loss improved from 11909506.00000 to 11897924.00000, saving model to model.h5\n",
            "248/248 - 1s - loss: 11897924.0000 - 527ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 80: loss improved from 11897924.00000 to 11886362.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11886362.0000 - 360ms/epoch - 1ms/step\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 81: loss improved from 11886362.00000 to 11874804.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11874804.0000 - 339ms/epoch - 1ms/step\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 82: loss improved from 11874804.00000 to 11863266.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11863266.0000 - 330ms/epoch - 1ms/step\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 83: loss improved from 11863266.00000 to 11851735.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11851735.0000 - 338ms/epoch - 1ms/step\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 84: loss improved from 11851735.00000 to 11840212.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11840212.0000 - 334ms/epoch - 1ms/step\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 85: loss improved from 11840212.00000 to 11828704.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11828704.0000 - 321ms/epoch - 1ms/step\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 86: loss improved from 11828704.00000 to 11817209.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11817209.0000 - 346ms/epoch - 1ms/step\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 87: loss improved from 11817209.00000 to 11805717.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11805717.0000 - 317ms/epoch - 1ms/step\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 88: loss improved from 11805717.00000 to 11794249.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11794249.0000 - 338ms/epoch - 1ms/step\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 89: loss improved from 11794249.00000 to 11782781.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11782781.0000 - 338ms/epoch - 1ms/step\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 90: loss improved from 11782781.00000 to 11771329.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11771329.0000 - 340ms/epoch - 1ms/step\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 91: loss improved from 11771329.00000 to 11759890.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11759890.0000 - 325ms/epoch - 1ms/step\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 92: loss improved from 11759890.00000 to 11748460.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11748460.0000 - 341ms/epoch - 1ms/step\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 93: loss improved from 11748460.00000 to 11737041.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11737041.0000 - 336ms/epoch - 1ms/step\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 94: loss improved from 11737041.00000 to 11725636.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11725636.0000 - 336ms/epoch - 1ms/step\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 95: loss improved from 11725636.00000 to 11714240.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11714240.0000 - 333ms/epoch - 1ms/step\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 96: loss improved from 11714240.00000 to 11702854.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11702854.0000 - 340ms/epoch - 1ms/step\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 97: loss improved from 11702854.00000 to 11691482.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11691482.0000 - 320ms/epoch - 1ms/step\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 98: loss improved from 11691482.00000 to 11680117.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11680117.0000 - 341ms/epoch - 1ms/step\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 99: loss improved from 11680117.00000 to 11668767.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11668767.0000 - 328ms/epoch - 1ms/step\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 100: loss improved from 11668767.00000 to 11657431.00000, saving model to model.h5\n",
            "248/248 - 0s - loss: 11657431.0000 - 333ms/epoch - 1ms/step\n",
            "End of NN training\n",
            "Model set\n",
            "Using size restricted mode (Could not find directory for cpxchecklic).\n",
            "CPLEX Error  1016: Community Edition. Problem size limits exceeded. Purchase at http://ibm.biz/error1016.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DOcplexLimitsExceeded",
          "evalue": "**** Promotional version. Problem size limits (1000 vars, 1000 consts) exceeded, model has 2550 vars, 167 consts, CPLEX code=1016",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCplexSolverError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docplex/mp/cplex_engine.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, mdl, parameters, **kwargs)\u001b[0m\n\u001b[1;32m   2043\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                 \u001b[0mcpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cplex/__init__.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, paramsets)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_MIP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m             \u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmipopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquadratic_constraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cplex/_internal/_procedural.py\u001b[0m in \u001b[0;36mmipopt\u001b[0;34m(env, lp)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPXXmipopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m     \u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cplex/_internal/_procedural.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, env, status, from_cb)\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0merror_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeterrorstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCplexSolverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCplexSolverError\u001b[0m: CPLEX Error  1016: Community Edition. Problem size limits exceeded. Purchase at http://ibm.biz/error1016.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mDOcplexLimitsExceeded\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-50212b3dfd0e>\u001b[0m in \u001b[0;36m<cell line: 690>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;31m#run DRL Variant 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m \u001b[0mSOL_FSTAGE_REW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSOLVALUE_REW1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mrun_DRL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDESTC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCAPV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mREWV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DRL_REW1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUMBERNODES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAXITER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLAST_SCENARIO_TO_TRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0mTIME_DRL_REW1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-50212b3dfd0e>\u001b[0m in \u001b[0;36mrun_DRL\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;31m#print(\"const5...\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m       \u001b[0mmsol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;31m#print(\"const6...\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmsol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docplex/mp/model.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4899\u001b[0m                 \u001b[0;31m# take arg clean flag or this model's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4900\u001b[0m                 \u001b[0mused_clean_before_solve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_before_solve'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_before_solve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4901\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_clean_before_solve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# lex_timelimits, lex_mipgaps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4902\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4903\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot solve model: no CPLEX runtime found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docplex/mp/model.py\u001b[0m in \u001b[0;36m_solve_local\u001b[0;34m(self, context, clean_before_solve, parameter_sets)\u001b[0m\n\u001b[1;32m   4947\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDOcplexException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdocpx_e\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4948\u001b[0m             \u001b[0mnew_solution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4949\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mdocpx_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4951\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docplex/mp/model.py\u001b[0m in \u001b[0;36m_solve_local\u001b[0;34m(self, context, clean_before_solve, parameter_sets)\u001b[0m\n\u001b[1;32m   4936\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_parameters_to_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mused_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4938\u001b[0;31m             new_solution = self_engine.solve(self,\n\u001b[0m\u001b[1;32m   4939\u001b[0m                                              \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mused_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4940\u001b[0m                                              \u001b[0mclean_before_solve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_before_solve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docplex/mp/cplex_engine.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, mdl, parameters, **kwargs)\u001b[0m\n\u001b[1;32m   2078\u001b[0m                 \u001b[0mcpx_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1016\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mcpx_status_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Promotional version. Problem size limits exceeded., CPLEX code=1016.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal_ce_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_multiobj_error_1300\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m1300\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcpx_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docplex/mp/model.py\u001b[0m in \u001b[0;36mfatal_ce_limits\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0mnb_constraints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal_limits_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_constraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docplex/mp/error_handler.py\u001b[0m in \u001b[0;36mfatal_limits_exceeded\u001b[0;34m(self, nb_vars, nb_constraints)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfatal_limits_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_constraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mdocplex_error_stop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDOcplexLimitsExceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_constraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDOcplexLimitsExceeded\u001b[0m: **** Promotional version. Problem size limits (1000 vars, 1000 consts) exceeded, model has 2550 vars, 167 consts, CPLEX code=1016"
          ]
        }
      ],
      "source": [
        "# Fixing random seeds\n",
        "#torch.manual_seed(1368)\n",
        "rs = np.random.RandomState(1368)\n",
        "YELLOW_TEXT = '\\033[93m'\n",
        "ENDC = '\\033[0m'\n",
        "BOLD = '\\033[1m'\n",
        "\n",
        "\n",
        "#Define algorithms parameters to be tracked and reported\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Define Auxiliary Functions\n",
        "\n",
        "#Heuristic callback for optimization step\n",
        "class DOHeurCallback(ModelCallbackMixin, HeuristicCallback):\n",
        "    def __init__(self, env):\n",
        "        HeuristicCallback.__init__(self, env)\n",
        "        ModelCallbackMixin.__init__(self)\n",
        "\n",
        "    @print_called('--> calling my_heuristic callback... #{0}')\n",
        "    def __call__(self):\n",
        "        feas = self.get_feasibilities()\n",
        "        var_indices = [j for j, f in enumerate(feas)] # if f ==self.feasibility_status.feasible]\n",
        "        #print(\"set solution0\")\n",
        "        if var_indices:\n",
        "            #print(\"set solution1\")\n",
        "            # this shows how to get back to the DOcplex variable from the index\n",
        "            # but is not necessary for the logic.\n",
        "            dvars = [self.index_to_var(v) for v in var_indices]\n",
        "            sol=self.make_solution_from_vars(dvars)\n",
        "            z_val =[]\n",
        "            s_val =[]\n",
        "            z_indices=[]\n",
        "            for i in range(NUMBERNODES):\n",
        "              s_val += sol.get_values([v for v in dvars if v.name=='s_'+str(i) ])\n",
        "            #print(\"set solution2\")\n",
        "            for i in range(len(DESTC)):\n",
        "              z_val += sol.get_values([v for v in dvars if v.name=='z_'+str(i) ])\n",
        "              z_indices += [v.index for v in dvars if v.name=='z_'+str(i)]\n",
        "            #Create Vector with Customer delivery order suggested by z_val\n",
        "            #print(\"set solution2\")\n",
        "            z_order = np.zeros(len(DESTC),dtype=int)\n",
        "            for i in range(len(DESTC)):\n",
        "              order = 1\n",
        "              for j in range(len(DESTC)):\n",
        "                if i != j:\n",
        "                  if z_val[j] < z_val[i]:\n",
        "                    order += 1\n",
        "              z_order[i]= order\n",
        "            #Now define heuristic for variables x using z_order\n",
        "            #print(\"set solution3\")\n",
        "            x_indices = []\n",
        "            x_val =[]\n",
        "            for i in range(len(DESTC)-1):\n",
        "              for j in range(i+1,len(DESTC)):\n",
        "                #print(i,j)\n",
        "                if z_order[i] < z_order[j]:\n",
        "                  x_val += [1]\n",
        "                  x_indices += [v.index for v in dvars if v.name=='x_'+str(i)+'_'+str(j)]\n",
        "                else:\n",
        "                  x_val += [0]\n",
        "                  x_indices += [v.index for v in dvars if v.name=='x_'+str(i)+'_'+str(j)]\n",
        "\n",
        "            #print('* rounded vars = [{0}]'.format(', '.join([v.name for v in dvars[:9]])))\n",
        "            #print(\"set solution\")\n",
        "            # -- calling set-solution in cplex callback class\n",
        "            self.set_solution([z_indices+x_indices, list(z_order)+x_val])\n",
        "\n",
        "\n",
        "# Lazy constraint callback to separate subtour elimination constraints.\n",
        "class DOLazyCallback(ConstraintCallbackMixin, LazyConstraintCallback):\n",
        "    def __init__(self, env):\n",
        "        LazyConstraintCallback.__init__(self, env)\n",
        "        ConstraintCallbackMixin.__init__(self)\n",
        "        #self.nb_lazy_cts = 0\n",
        "\n",
        "\n",
        "    @print_called('--> lazy constraint callback called: #{0}')\n",
        "    def __call__(self):\n",
        "        feas = self.get_feasibilities()\n",
        "        var_indices = [j for j, f in enumerate(feas)]\n",
        "        z_val =[]\n",
        "        s_val =[]\n",
        "        y_val =[]\n",
        "        x_val =[]\n",
        "        z_indices=[]\n",
        "        s_indices=[]\n",
        "        y_indices=[]\n",
        "        x_indices=[]\n",
        "        if var_indices:\n",
        "          # this shows how to get back to the DOcplex variable from the index\n",
        "          # but is not necessary for the logic.\n",
        "          dvars = [self.index_to_var(v) for v in var_indices]\n",
        "          sol=self.make_solution_from_vars(dvars)\n",
        "          for i in range(NUMBERNODES):\n",
        "            s_val += sol.get_values([v for v in dvars if v.name=='s_'+str(i)])\n",
        "            y_val += sol.get_values([v for v in dvars if v.name=='y_'+str(i)])\n",
        "            s_indices += [v.index for v in dvars if v.name=='s_'+str(i)]\n",
        "            y_indices += [v.index for v in dvars if v.name=='y_'+str(i)]\n",
        "          for i in range(len(DESTC)):\n",
        "            z_val += sol.get_values([v for v in dvars if v.name=='z_'+str(i)])\n",
        "            z_indices += [v.index for v in dvars if v.name=='z_'+str(i)]\n",
        "            x_valrow=[]\n",
        "            x_indicesrow=[]\n",
        "            for j in range(len(DESTC)):\n",
        "              x_valrow += sol.get_values([v for v in dvars if v.name=='x_'+str(i)+'_'+str(j)])\n",
        "              x_indicesrow += [v.index for v in dvars if v.name=='x_'+str(i)+'_'+str(j)]\n",
        "            x_indicesrow =  [0.0] * (i+1)+x_indicesrow\n",
        "            x_valrow =  [0.0 ]* (i+1)+x_valrow\n",
        "            x_val.append(x_valrow)\n",
        "            x_indices.append(x_indicesrow)\n",
        "          for i in range(len(DESTC)):\n",
        "            for j in range(len(DESTC)):\n",
        "              for k in range(len(DESTC)):\n",
        "                #print(i,j,k)\n",
        "                if i > j and j < k and k < i and -x_val[j][i]+x_val[j][k]+x_val[k][i]>1:\n",
        "                  #print(\"1...\")\n",
        "                  lhs,sense,rhs= self.linear_ct_to_cplex(-self.index_to_var(x_indices[j][i])+ self.index_to_var(x_indices[j][k])+ self.index_to_var(x_indices[k][i])<=1)\n",
        "                  self.add(lhs,sense,rhs)\n",
        "                  return\n",
        "                elif i < j and j > k and k < i and x_val[i][j]-x_val[k][j]+x_val[k][i]>1:\n",
        "                  #print(\"2...\")\n",
        "                  lhs,sense,rhs= self.linear_ct_to_cplex(self.index_to_var(x_indices[i][j])-self.index_to_var(x_indices[k][j])+self.index_to_var(x_indices[k][i])<=1)\n",
        "                  self.add(lhs,sense,rhs)\n",
        "                  return\n",
        "                elif i > j and j > k and k < i and -x_val[j][i]-x_val[k][j]+ x_val[k][i]>0:\n",
        "                  #print(\"3...\")\n",
        "                  lhs,sense,rhs= self.linear_ct_to_cplex(-self.index_to_var(x_indices[j][i])-self.index_to_var(x_indices[k][j])+self.index_to_var(x_indices[k][i])<=0)\n",
        "                  self.add(lhs,sense,rhs)\n",
        "                  return\n",
        "                elif i < j and j < k and k > i and x_val[i][j]+x_val[j][k]-x_val[i][k]>1:\n",
        "                  #print(\"4...\")\n",
        "                  lhs,sense,rhs= self.linear_ct_to_cplex(self.index_to_var(x_indices[i][j])+self.index_to_var(x_indices[j][k])-self.index_to_var(x_indices[i][k]) <=1)\n",
        "                  self.add(lhs,sense,rhs)\n",
        "                  return\n",
        "                elif i > j and j < k and k > i and -x_val[j][i]+x_val[j][k]-x_val[i][k]>0:\n",
        "                  #print(\"5...\")\n",
        "                  lhs,sense,rhs= self.linear_ct_to_cplex(-self.index_to_var(x_indices[j][i])+self.index_to_var(x_indices[j][k])-self.index_to_var(x_indices[i][k]<=0))\n",
        "                  self.add(lhs,sense,rhs)\n",
        "                  return\n",
        "                elif i < j and j > k and k > i and x_val[i][j]-x_val[k][j]-x_val[i][k]>0:\n",
        "                  #print(\"6...\")\n",
        "                  lhs,sense,rhs= self.linear_ct_to_cplex(self.index_to_var(x_indices[i][j])-self.index_to_var(x_indices[k][j])-self.index_to_var(x_indices[i][k]) <=0)\n",
        "                  self.add(lhs,sense,rhs)\n",
        "                  return\n",
        "                elif i > j and j > k and k > i and -x_val[j][i]-x_val[k][j]-x_val[i][k]>-1:\n",
        "                  #print(\"7...\")\n",
        "                  lhs,sense,rhs= self.linear_ct_to_cplex(-self.index_to_var(x_indices[j][i])-self.index_to_var(x_indices[k][j])-self.index_to_var(x_indices[i][k])<=-1)\n",
        "                  self.add(lhs,sense,rhs)\n",
        "                  return\n",
        "\n",
        "          for node in range(NUMBERNODES):\n",
        "            m2 = Model(name='sepprob',log_output=False)\n",
        "            m2.context.cplex_parameters.timelimit = 600\n",
        "\n",
        "            neta = m2.binary_var_list(len(DESTC), name=\"n\")\n",
        "            m2.set_objective(\"min\", sum( neta[i]*first_layer_weights[i,node]*(z_val[i]-L[node,i]*(1-s_val[node])) for i in range(len(DESTC)) if first_layer_weights[i,node] != 0)\n",
        "      + s_val[node]*(first_layer_biases[node]+ sum((1-neta[i])*U[node,i]*first_layer_weights[i,node] for i in range(len(DESTC)) if first_layer_weights[i,node] == 0) ))\n",
        "\n",
        "\n",
        "\n",
        "            m2.add_constraints_( (neta[i]<=1 for i in range(len(DESTC))))\n",
        "\n",
        "            msol2=m2.solve()\n",
        "            if not msol2.is_empty() and msol2.get_objective_value() < y_val[node]:\n",
        "              neta_val = msol2.get_values([neta[ind] for ind in range(len(DESTC)) ])\n",
        "              lhs,sense,rhs= self.linear_ct_to_cplex(self.index_to_var(y_indices[node]) <= sum(neta_val[i]*first_layer_weights[i,node]*(self.index_to_var(z_indices[i])-L[node,i]*(1-self.index_to_var(s_indices[node]))) for i in range(len(DESTC)) if first_layer_weights[i,node] != 0) + self.index_to_var(s_indices[node])*((1-neta_val[i])*first_layer_biases[node]+ sum((1-neta_val[i])*U[node,i]*first_layer_weights[i,node] for i in range(len(DESTC)) if first_layer_weights[i,node] != 0)))\n",
        "              self.add(lhs,sense,rhs)\n",
        "              break\n",
        "\n",
        "\n",
        "\n",
        "# Calculate Reward for Variant 1 of Problem\n",
        "def calculate_reward1(A,DURV,REWV,CAPV,DESTC,firststage,episode):\n",
        "    episodecost=0\n",
        "    laststop = 0 #depot\n",
        "    cap = 0\n",
        "    time = 0\n",
        "    for i in range(len(DESTC)): # ordering positions\n",
        "      if scenario[episode][DESTC.index(firststage[i])] == 1 and scenario[episode][len(DESTC) +DESTC.index(firststage[i])] == 0:\n",
        "        if time + A[laststop, firststage[i]] + A[firststage[i], 0] <= DURV:\n",
        "          episodecost += REWV*A[laststop,firststage[i]]\n",
        "          time += A[laststop,firststage[i]]\n",
        "          laststop = firststage[i]\n",
        "          cap += 1\n",
        "          if i == len(DESTC)-1:\n",
        "            episodecost += REWV*A[firststage[i], 0]\n",
        "          elif cap == CAPV:\n",
        "            episodecost += REWV*A[laststop, 0]\n",
        "            laststop = 0\n",
        "            cap = 0\n",
        "            time = 0\n",
        "        else :\n",
        "          if i == len(DESTC)-1: # assume 2*time from depot to i ≤ D always\n",
        "            episodecost += REWV*A[laststop, 0] + REWV*A[0,firststage[i]] + REWV*A[firststage[i], 0]\n",
        "          else :\n",
        "            episodecost += REWV*A[laststop, 0] + REWV*A[0, firststage[i]]\n",
        "            time = A[0, firststage[i]]\n",
        "            laststop = firststage[i]\n",
        "            cap = 1\n",
        "      elif scenario[episode][DESTC.index(firststage[i])] == 1 and scenario[episode][len(DESTC) +DESTC.index(firststage[i])] == 1:\n",
        "        episodecost += PRICEOD[DESTC.index(firststage[i])]\n",
        "        if i == len(DESTC)-1 and cap !=0:\n",
        "          episodecost += REWV*A[laststop, 0]\n",
        "      elif i == len(DESTC)-1 and cap !=0:\n",
        "        episodecost += REWV*A[laststop, 0]\n",
        "\n",
        "    return episodecost\n",
        "\n",
        "\n",
        "\n",
        "# Calculate Reward for Heuristic Variant 2 of Problem\n",
        "def calculate_reward2heuristic(A,DURV,REWV,CAPV,DESTC,firststage,scenario,episode):\n",
        "\n",
        "    laststop = 0 #depot\n",
        "    cap = 0\n",
        "    time = 0\n",
        "    continuo = True\n",
        "    bypass = False\n",
        "    episodecost = 0\n",
        "    i = -1\n",
        "    while continuo:\n",
        "      i +=1\n",
        "      if scenario[episode][DESTC.index(firststage[i])] == 1 and (scenario[episode][len(DESTC) +DESTC.index(firststage[i])] == 0 or bypass):\n",
        "        bypass = False\n",
        "        if time + A[laststop, firststage[i]] + A[firststage[i], 0] <= DURV :\n",
        "          episodecost += REWV*A[laststop,firststage[i]]\n",
        "          time += A[laststop,firststage[i]]\n",
        "          laststop = firststage[i]\n",
        "          cap += 1\n",
        "          if i == len(DESTC)-1:\n",
        "            episodecost += REWV*A[firststage[i], 0]\n",
        "            continuo = False\n",
        "          elif cap == CAPV:\n",
        "            episodecost += REWV*A[laststop, 0]\n",
        "            laststop = 0\n",
        "            cap = 0\n",
        "            time = 0\n",
        "        else :\n",
        "          if i == len(DESTC)-1: # assume 2*time from depot to i <= timelimit always\n",
        "            episodecost += REWV*A[laststop, 0] + REWV*A[0, firststage[i]] + REWV*[firststage[i], 0]\n",
        "            continuo = False\n",
        "          else :\n",
        "            episodecost += REWV*A[laststop, 0] + REWV*A[0, firststage[i]]\n",
        "            time = A[0, firststage[i]]\n",
        "            laststop = firststage[i]\n",
        "            cap = 1\n",
        "      elif scenario[episode][DESTC.index(firststage[i])] == 1 and scenario[episode][len(DESTC) +DESTC.index(firststage[i])] == 1:\n",
        "        # find next customer available\n",
        "        j = i+1\n",
        "        while j <= len(DESTC)-1 and scenario[episode][DESTC.index(firststage[j])] == 0 :\n",
        "          j += 1\n",
        "        if j <= len(DESTC)-1 and PRICEOD[DESTC.index(firststage[i])] <= REWV*A[laststop, firststage[i]] + REWV*A[firststage[i],firststage[j]]:\n",
        "          episodecost += PRICEOD[DESTC.index(firststage[i])]\n",
        "          i = j-1\n",
        "        elif j > len(DESTC)-1 and PRICEOD[DESTC.index(firststage[i])] <= REWV*A[laststop, firststage[i]] + REWV*A[firststage[i], 0]:\n",
        "          continuo = False\n",
        "          episodecost += PRICEOD[DESTC.index(firststage[i])]\n",
        "          if cap != 0:\n",
        "            episodecost += REWV*A[laststop, 0]\n",
        "        elif j <= len(DESTC)-1 and PRICEOD[DESTC.index(firststage[i])] > REWV*A[laststop, firststage[i]] + REWV*A[firststage[i],firststage[j]]:\n",
        "          bypass = True\n",
        "          i -= 1\n",
        "        elif j > len(DESTC)-1 and PRICEOD[DESTC.index(firststage[i])] > REWV*A[laststop, firststage[i]] + REWV*A[firststage[i], 0]:\n",
        "          bypass = True\n",
        "          i -= 1\n",
        "      else :\n",
        "        if i == len(DESTC)-1 and cap !=0:\n",
        "          episodecost += REWV*A[laststop, 0]\n",
        "        if i == len(DESTC)-1:\n",
        "          continuo = False\n",
        "    return episodecost\n",
        "\n",
        "\n",
        "\n",
        "#Generate Instance\n",
        "def getdata(inst_id):\n",
        "    #Define size of grid to define Graph\n",
        "    grid= 100 #will be a 10 x 10 euclidean grid to include depot, customers and ODs\n",
        "\n",
        "    #Define graph G(V,A)\n",
        "    V = list(range(grid * grid)) #Depot is vertice/node 0 locate in grid position (0,0)\n",
        "    A= np.zeros((grid * grid,grid * grid))\n",
        "    for i in V:                    #i is a vertice/node within the grid\n",
        "      for j in V:    #j is a vertice/node within the grid\n",
        "        A[i,j] = math.sqrt( (i//grid - j//grid)**2 + (i%grid - j%grid)**2)     #building complete graph\n",
        "\n",
        "    #Create Instances Variables\n",
        "    DESTC = []\n",
        "    PROBC= []\n",
        "    REWV = 0\n",
        "    CAPV = 0\n",
        "    DURV = 1000000000000\n",
        "    REWOD= []\n",
        "    PROBOD= []\n",
        "\n",
        "    if inst_id[-1] == '0':\n",
        "      siz=int(inst_id)\n",
        "      #Define customers Destination nodes, marginal probabilities, capacities\n",
        "      DESTC = random.sample(list(range(1,grid*grid)),siz)\n",
        "      DESTC = [int(round(x)) for x in DESTC]\n",
        "      #print(DESTC)\n",
        "      PROBC = [random.choice(np.arange(0.1,0.3,0.1)) for _ in range(siz) ]\n",
        "      #print(PROBC)\n",
        "      REWV = 2\n",
        "      CAPV = siz/3 #demand is given in demands unit, each customer is fixed at one unit\n",
        "      REWOD= []\n",
        "      PROBOD= [random.choice(np.arange(0.1,0.3,0.1)) for _ in range(siz) ]\n",
        "      #print(PROBOD)\n",
        "      #input()\n",
        "    else:\n",
        "      print(\"NO INSTANCES FOUND\")\n",
        "\n",
        "\n",
        "    return V,A,DESTC,PROBC,REWV,CAPV,DURV,PROBOD,REWOD\n",
        "\n",
        "\n",
        "\n",
        "print(\"Main Program started\")\n",
        "\n",
        "\n",
        "#Define where to store results\n",
        "f = open('./RESULTDRL.csv', 'a', encoding='UTF8', newline='')\n",
        "# create the csv writer\n",
        "writer = csv.writer(f)\n",
        "\n",
        "###############################################################################\n",
        "#Define variables to be reported to control performance of different algorithms\n",
        "RESULT_SIMU_REW1 = 0\n",
        "RESULT_SIMU_REW1_RAND = 0\n",
        "RESULT_SIMU_REW2E = 0\n",
        "RESULT_SIMU_REW2H = 0\n",
        "RESULT_SIMU_DRO = 0\n",
        "RESULT_SIMU_REOPT = 0\n",
        "\n",
        "SOL_FSTAGE_REW1 = 0\n",
        "SOL_FSTAGE_REW2E = 0\n",
        "SOL_FSTAGE_REW2H = 0\n",
        "SOL_FSTAGE_DRO = 0\n",
        "\n",
        "SOLVALUE_REW1 = 0\n",
        "SOLVALUE_REW2E = 0\n",
        "SOLVALUE_REW2H = 0\n",
        "SOLVALUE_DRO = 0\n",
        "\n",
        "TIME_DRL_REW1 = 0\n",
        "TIME_DRL_REW2E = 0\n",
        "TIME_DRL_REW2H = 0\n",
        "TIME_DRO = 0\n",
        "\n",
        "TOTAL_OD_DECISIONS = 0\n",
        "TOTAL_OD_ALLOCATIONS = 0\n",
        "\n",
        "ALGOS = [\"DRL_REW1\",\"DRL_REW2E\",\"DRL_REW2H\",\"DRO\",\"REPOT\"]\n",
        "\n",
        "ALGO=\"DRL_REW1\"\n",
        "\n",
        "#size of instance\n",
        "#key parameters of NN (See later below)\n",
        "  ##number of iterations\n",
        "  ##epsilon\n",
        "  ##learning rate\n",
        "  ##number of nodes\n",
        "  ##epochs\n",
        "  ##batchsize\n",
        "  ##number of scenarios to train\n",
        "  ##number of scenarios to simulate\n",
        "#instance id see below\n",
        "\n",
        "#Define information (header) to be stored as result\n",
        "header = [datetime.datetime.now(),'Instance', 'Algorithm','# Iterations','Epsilon','Learning rate','# Nodes','EPOCHS','BATCH','# Scen Train','Sol Value REW1','Time REW1','Sol Value REW2E','Time REW2E', 'Sol Value REW2H','Time REW2H','Sol Value DRO','Time DRO','Result Simu REW1','Result Simu REW1 Random','Result Simu REW2E','Result Simu REW2H','Result Simu DRO','Result Simu REOPT', 'TOTAL_OD_DECISIONS','TOTAL_OD_ALLOCATIONS']\n",
        "\n",
        "writer.writerow(header)\n",
        "###############################################################################\n",
        "\n",
        "#Read Instance Data\n",
        "print(\"Read Instance Data\")\n",
        "inst_id =\"70\"\n",
        "V,A,DESTC,PROBC,REWV,CAPV,DURV,PROBOD,REWOD= getdata(inst_id)\n",
        "\n",
        "#Calculate minimum price to pay for ODs\n",
        "PRICEOD = [float('inf') for _ in range(len(DESTC))]\n",
        "DESTC1=DESTC + [0]\n",
        "for i in DESTC:\n",
        "  for j in DESTC1:\n",
        "    for r in DESTC1:\n",
        "      if (j !=r and j != i and r != i) or (j==0 and r==0):\n",
        "        if PRICEOD[DESTC.index(i)] > REWV*(A[j,i] + A[i,r] - A[j,r]):\n",
        "           PRICEOD[DESTC.index(i)] = REWV*(A[j,i] + A[i,r]- A[j,r])\n",
        "           if PRICEOD[DESTC.index(i)] <= 0.001:\n",
        "             PRICEOD[DESTC.index(i)] =0.1\n",
        "\n",
        "print(\"Instance \", inst_id,\"  has been loaded\")\n",
        "\n",
        "#Prepare two groups of scenarios (Evaluation and Simulation)\n",
        "#Create vectors for training scenarios-policy evaluation  + simulation scenarios -compare different algorithm\n",
        "LAST_SCENARIO_TO_GENERATE= 100000 #1 EPISODE CONTAINS 4 SCENARIOS (HARDCODED)\n",
        "LAST_SCENARIO_TO_TRAIN= 99000\n",
        "FIRST_SCENARIO_TO_SIMULATE= 99000\n",
        "LAST_SCENARIO_TO_SIMULATE= 100000\n",
        "\n",
        "print(\"Going to Generate Scenarios for training...\")\n",
        "scenario = []\n",
        "\n",
        "for numsce in range(1,LAST_SCENARIO_TO_GENERATE):\n",
        "  #Will store 4 samples (4 stages in time horizon, per day)\n",
        "  SAMPLETEST = np.zeros(2*len(DESTC)) #1\n",
        "  ACCUMTEST = np.zeros(2*len(DESTC))\n",
        "  x2 = np.random.randint(1,11,2*len(DESTC))\n",
        "  for i in range(len(DESTC)):\n",
        "    if x2[i] <= PROBC[i]*10:\n",
        "      SAMPLETEST[i]=1\n",
        "  for i in range(len(DESTC),2*len(DESTC)):\n",
        "    if SAMPLETEST[i- len(DESTC)]== 1 and x2[i] <= PROBOD[i- len(DESTC)]*10:\n",
        "      SAMPLETEST[i]=1\n",
        "  scenario.append(SAMPLETEST)\n",
        "  ACCUMTEST += SAMPLETEST\n",
        "\n",
        "  SAMPLETEST = np.zeros(2*len(DESTC)) #2\n",
        "  x2 = np.random.randint(1,11,2*len(DESTC))\n",
        "  for i in range(len(DESTC)):\n",
        "    if ACCUMTEST[i]==0 and x2[i] <= PROBC[i]*10:\n",
        "      SAMPLETEST[i]=1\n",
        "  for i in range(len(DESTC),2*len(DESTC)):\n",
        "    if SAMPLETEST[i- len(DESTC)]== 1 and x2[i] <= PROBOD[i- len(DESTC)]*10:\n",
        "      SAMPLETEST[i]=1\n",
        "  scenario.append(SAMPLETEST)\n",
        "  ACCUMTEST += SAMPLETEST\n",
        "\n",
        "  SAMPLETEST = np.zeros(2*len(DESTC)) #3\n",
        "  x2 = np.random.randint(1,11,2*len(DESTC))\n",
        "  for i in range(len(DESTC)):\n",
        "    if ACCUMTEST[i]==0 and x2[i] <= PROBC[i]*10:\n",
        "      SAMPLETEST[i]=1\n",
        "  for i in range(len(DESTC),2*len(DESTC)):\n",
        "    if SAMPLETEST[i- len(DESTC)]== 1 and x2[i] <= PROBOD[i- len(DESTC)]*10:\n",
        "      SAMPLETEST[i]=1\n",
        "  scenario.append(SAMPLETEST)\n",
        "  ACCUMTEST += SAMPLETEST\n",
        "\n",
        "  SAMPLETEST = np.zeros(2*len(DESTC))\n",
        "  x2 = np.random.randint(1,11,2*len(DESTC))\n",
        "  for i in range(len(DESTC)):\n",
        "    if ACCUMTEST[i]==0 and x2[i] <= PROBC[i]*10:\n",
        "      SAMPLETEST[i]=1\n",
        "  for i in range(len(DESTC),2*len(DESTC)):\n",
        "    if SAMPLETEST[i- len(DESTC)]== 1 and x2[i] <= PROBOD[i- len(DESTC)]*10:\n",
        "      SAMPLETEST[i]=1\n",
        "  scenario.append(SAMPLETEST)\n",
        "  ACCUMTEST += SAMPLETEST\n",
        "\n",
        "\n",
        "print(\"All Scenarios for Policy Evaluation and Simulation Generated...\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Solve the RL algorithm\n",
        "\n",
        "#Define Key parameters\n",
        "epsilon = 0.6 #must vary in steps of 5%\n",
        "NUMBERNODES = 32\n",
        "#Main.NUMBERNODES = NUMBERNODES\n",
        "learning_rate=0.000001\n",
        "MAXITER = 15\n",
        "epoch=100\n",
        "batch=100\n",
        "\n",
        "#Function ro run different DRL algorithms\n",
        "def run_DRL(DESTC,CAPV,REWV,ALGO,NUMBERNODES,scenario,epsilon,learning_rate,MAXITER,LAST_SCENARIO_TO_TRAIN) :\n",
        "    #Initialize policy (z0 and epsilon)\n",
        "    bestZ = np.random.permutation(list(range(1,len(DESTC)+1)))\n",
        "    bestZ = [int(round(x)) for x in bestZ]\n",
        "\n",
        "    #Initialize Neural Networks\n",
        "    print(\"Initialize NN\")\n",
        "    model = Sequential()\n",
        "    model.add(Dense(NUMBERNODES, input_shape=(len(DESTC),), activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    sgd = SGD(learning_rate) #Learning rate\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=sgd)\n",
        "    # define the checkpoint\n",
        "    filepath = \"model.h5\"\n",
        "\n",
        "\n",
        "    #Loop Policy Iteration\n",
        "\n",
        "      #With policy and Scenarios and Reward Function Update Value Function Table\n",
        "\n",
        "    #Generate value function for all first-stage decisions using first variant recourse\n",
        "    #By doing that already select the best first-stage decision\n",
        "\n",
        "    for ITER in range(MAXITER):\n",
        "      print(\"Initiating Value Function evaluation for algo \", ALGO,\" Iter= \",ITER)\n",
        "      episode =0\n",
        "      Value_function_zeta = []\n",
        "      Value_function = []\n",
        "      firststage = [0 for _ in range(len(DESTC))]\n",
        "      while episode < LAST_SCENARIO_TO_TRAIN:\n",
        "        zetatest = bestZ\n",
        "        if random.randint(1,20) <= epsilon*10*2:\n",
        "          zetatest = np.random.permutation(list(range(1,len(DESTC)+1)))\n",
        "          zetatest = [int(round(x)) for x in zetatest]\n",
        "        for i in range(len(DESTC)):\n",
        "          firststage[zetatest[i]-1]= DESTC[i]\n",
        "        episodecost = 0\n",
        "        for _ in range(4):\n",
        "          if ALGO == \"DRL_REW1\" :\n",
        "                    episodecost+=calculate_reward1(A,DURV,REWV,CAPV,DESTC,firststage,episode)\n",
        "          elif ALGO == \"DRL_REW2H\" :\n",
        "                    episodecost+=calculate_reward2heuristic(A,DURV,REWV,CAPV,DESTC,firststage,scenario,episode)\n",
        "          elif ALGO == \"DRL_REW2E\" :\n",
        "            #calculate reward 2 exact for this scenario\n",
        "            Main.scenario = scenario[episode]\n",
        "            Main.firststage = firststage\n",
        "            RES1,RES3,RES2 = jl.eval(\"rewardvariant2(V,A,REWV,PRICEOD,DESTC,scenario,firststage)\")\n",
        "            episodecost +=RES2\n",
        "            print(episode)\n",
        "          else :\n",
        "            print(\"No ALGO to run\")\n",
        "            input()\n",
        "          episode += 1\n",
        "        #print(zetatest,\" , \",episodecost)\n",
        "        #input()\n",
        "        Value_function_zeta.append(zetatest)\n",
        "        Value_function.append(episodecost)\n",
        "\n",
        "      print(\"Value Function table mount has ended\")\n",
        "      with open('objs.pkl', 'wb') as f:  # Python: open(..., 'w')\n",
        "        pickle.dump(scenario, f)\n",
        "      del scenario\n",
        "      gc.collect()\n",
        "\n",
        "      #Use Value Function table to incremmentally train Neural network\n",
        "      # train the model using SGD\n",
        "      print(\"[INFO] training network...\")\n",
        "      checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "      callbacks_list = [checkpoint]\n",
        "      H = model.fit(Value_function_zeta, Value_function,epochs=epoch, batch_size=batch,   callbacks=callbacks_list,verbose=2)\n",
        "\n",
        "\n",
        "\n",
        "      #Use NN parameters to formulate MIP for Policy Improvement\n",
        "      global first_layer_weights\n",
        "      global first_layer_biases\n",
        "      global second_layer_weights\n",
        "      global second_layer_biases\n",
        "      global MHIGH\n",
        "      global MLOW\n",
        "      global L\n",
        "      global U\n",
        "      first_layer_weights = model.layers[0].get_weights()[0]\n",
        "      first_layer_biases  = model.layers[0].get_weights()[1]\n",
        "      second_layer_weights = model.layers[1].get_weights()[0]\n",
        "      second_layer_biases  = model.layers[1].get_weights()[1]\n",
        "\n",
        "      print(\"End of NN training\")\n",
        "\n",
        "\n",
        "      #Solve MIP and get new policy (z and epsilon)\n",
        "\n",
        "      MHIGH = np.zeros(NUMBERNODES)\n",
        "      MLOW = np.zeros(NUMBERNODES)\n",
        "      LOW = 0\n",
        "      UPPER = len(DESTC)+1\n",
        "      L=np.zeros((NUMBERNODES,len(DESTC)))\n",
        "      U=np.zeros((NUMBERNODES,len(DESTC)))\n",
        "\n",
        "      for i in range(NUMBERNODES):\n",
        "        for j in range(len(DESTC)):\n",
        "          if first_layer_weights[j,i] < 0 :\n",
        "            L[i,j]= UPPER\n",
        "            U[i,j]= LOW\n",
        "          else :\n",
        "            L[i,j]= LOW\n",
        "            U[i,j]= UPPER\n",
        "\n",
        "      for i  in range(NUMBERNODES):\n",
        "        MHIGH[i]= sum(first_layer_weights[j,i]*U[i,j] for j in range(len(DESTC))) + first_layer_biases[i]\n",
        "        MLOW[i]= sum(first_layer_weights[j,i]*L[i,j] for j in range(len(DESTC))) + first_layer_biases[i]\n",
        "\n",
        "\n",
        "      m = Model(name='BestOptz',log_output=True)\n",
        "      #m.context.cplex_parameters.threads = 1\n",
        "      m.context.cplex_parameters.timelimit = 2400\n",
        "      #m.context.cplex_parameters.workmem= 256\n",
        "      #m.context.cplex_parameters.mip.strategy.file=2\n",
        "      #cplex.setParam(IloCplex::WorkMem, 1024);\n",
        "      #cplex.setParam(IloCplex::NodeFileInd,2);\n",
        "      print(\"Model set\")\n",
        "\n",
        "      y = m.continuous_var_list(NUMBERNODES, name='y')\n",
        "\n",
        "      s = m.binary_var_list(NUMBERNODES, name=\"s\")\n",
        "\n",
        "      z = m.continuous_var_list(len(DESTC), lb=1, ub=len(DESTC), name='z')\n",
        "\n",
        "      x = m.binary_var_dict(((i, j) for i in range(len(DESTC)) for j in range(len(DESTC)) if i < j), name='x')\n",
        "\n",
        "      obj = m.continuous_var(name='obj')\n",
        "\n",
        "      m.set_objective(\"min\", obj)\n",
        "      #print(\"There goes variables\")\n",
        "\n",
        "      m.add_constraint_(obj >= sum(second_layer_weights[i,0]*y[i] for i in range(NUMBERNODES)) + second_layer_biases[0], ctname=\"const1\" )\n",
        "      #print(\"const1...\")\n",
        "\n",
        "      m.add_constraints_( (y[i] >= sum( first_layer_weights[j,i]*z[j] for j in range(len(DESTC)) )   + first_layer_biases[i] for i in range(NUMBERNODES) ))\n",
        "\n",
        "      m.add_constraints_( (y[i] <= sum( first_layer_weights[j,i]*z[j] for j in range(len(DESTC)) )   + first_layer_biases[i]  - MLOW[i]*(1-s[i]) for i in range(NUMBERNODES)))\n",
        "\n",
        "      m.add_constraints_( (y[i] <= MHIGH[i]*s[i] for i in range(NUMBERNODES)))\n",
        "\n",
        "      #print(\"const2...\")\n",
        "      #No strengthen constraints\n",
        "\n",
        "      m.add_constraints_( ( x[i,j]+x[j,k]+x[k,i]<=2 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i < j and j < k and k < i) )\n",
        "      #print(\"const3...\")\n",
        "\n",
        "      #m.add_constraints_( ( -x[j,i]+x[j,k]+x[k,i]<=1 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i > j and j < k and k < i ))\n",
        "\n",
        "      #m.add_constraints_( ( x[i,j]-x[k,j]+x[k,i]<=1 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i < j and j > k and k < i ))\n",
        "\n",
        "      #m.add_constraints_( ( -x[j,i]-x[k,j]+x[k,i]<=0 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if  i > j and j > k and k < i))\n",
        "\n",
        "      #m.add_constraints_( (x[i,j]+x[j,k]-x[i,k]<=1 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i < j and j < k and k > i ))\n",
        "\n",
        "      #m.add_constraints_( ( -x[j,i]+x[j,k]-x[i,k]<=0 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i > j and j < k and k > i))\n",
        "\n",
        "      #m.add_constraints_( ( x[i,j]-x[k,j]-x[i,k]<=0 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i < j and j > k and k > i))\n",
        "\n",
        "      #m.add_constraints_( (-x[j,i]-x[k,j]-x[i,k]<=-1  for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i > j and j > k and k > i ))\n",
        "\n",
        "      m.add_constraints_( ( z[i] == 1+sum(1-x[i,j] for j in range(len(DESTC)) if i < j ) + sum(x[j,i] for j in range(len(DESTC)) if i > j ) for i in range(len(DESTC)) ))\n",
        "\n",
        "      m.register_callback(DOHeurCallback)\n",
        "      cb = m.register_callback(DOLazyCallback)\n",
        "      #cb.cts = []\n",
        "      #cb.cts += [ -x[j,i]+x[j,k]+x[k,i]<=1 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i > j and j < k and k < i ]\n",
        "\n",
        "\n",
        "      #cb.cts += [x[i,j]-x[k,j]+x[k,i]<=1 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i < j and j > k and k < i ]\n",
        "\n",
        "      #cb.cts += [-x[j,i]-x[k,j]+x[k,i]<=0 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if  i > j and j > k and k < i]\n",
        "\n",
        "      #cb.cts += [x[i,j]+x[j,k]-x[i,k]<=1 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i < j and j < k and k > i ]\n",
        "\n",
        "      #cb.cts += [-x[j,i]+x[j,k]-x[i,k]<=0 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i > j and j < k and k > i]\n",
        "\n",
        "      #cb.cts += [x[i,j]-x[k,j]-x[i,k]<=0 for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i < j and j > k and k > i]\n",
        "\n",
        "      #cb.cts += [-x[j,i]-x[k,j]-x[i,k]<=-1  for i in range(len(DESTC)) for j in range(len(DESTC)) for k in range(len(DESTC)) if i > j and j > k and k > i ]\n",
        "      #print(\"const4...\")\n",
        "      #warmstart to guarantee at least one solution\n",
        "      warmstart=m.new_solution()\n",
        "      order_warmstart = sorted(DESTC)\n",
        "      for i in range(len(DESTC)-1):\n",
        "        for j in range(i+1,len(DESTC)):\n",
        "         if DESTC.index(order_warmstart[i]) < DESTC.index(order_warmstart[j]):   warmstart.add_var_value(x[DESTC.index(order_warmstart[i]),DESTC.index(order_warmstart[j])], 1)\n",
        "         else :\n",
        "           warmstart.add_var_value(x[DESTC.index(order_warmstart[j]),DESTC.index(order_warmstart[i])], 0)\n",
        "      m.add_mip_start(warmstart)\n",
        "\n",
        "      #print(\"const5...\")\n",
        "      msol=m.solve()\n",
        "      #print(\"const6...\")\n",
        "      if msol.is_empty():\n",
        "        print(\"The optbestz model was not solved correctly.\")\n",
        "        bestZ= [i for i in range(1,len(DESTC)+1)]\n",
        "        random.shuffle(bestZ)\n",
        "        objZ= 0\n",
        "        termination_status=\"NoSolution\"\n",
        "      else :\n",
        "        bestZ = msol.get_values([z[ind] for ind in range(len(DESTC)) ])\n",
        "        bestZ = [int(round(x)) for x in bestZ]\n",
        "        objZ= msol.get_objective_value()\n",
        "        termination_status=\"OK\"\n",
        "      print(bestZ,\" ,\",objZ,\" Iter= \",ITER)\n",
        "      # Getting back the objects:\n",
        "      #global scenario\n",
        "      with open('objs.pkl', 'rb') as f:  # Python : open(...)\n",
        "        scenario = pickle.load(f)\n",
        "    return bestZ, objZ\n",
        "\n",
        "#Sequence of Procedures to run different algorithms to Problem Instance\n",
        "#run DRL Variant 1\n",
        "start_time = time()\n",
        "SOL_FSTAGE_REW1,SOLVALUE_REW1 =run_DRL(DESTC,CAPV,REWV,'DRL_REW1',NUMBERNODES,scenario,epsilon,learning_rate,MAXITER,LAST_SCENARIO_TO_TRAIN)\n",
        "TIME_DRL_REW1= time()-start_time\n",
        "\n",
        "#run DRL Variant 2 Heuristic\n",
        "start_time = time()\n",
        "#SOL_FSTAGE_REW2H,SOLVALUE_REW2H =run_DRL(DESTC,CAPV,REWV,'DRL_REW2H',NUMBERNODES,scenario,epsilon,learning_rate,MAXITER,LAST_SCENARIO_TO_TRAIN)\n",
        "TIME_DRL_REW2H= time()-start_time\n",
        "SOL_FSTAGE_REW2H=SOL_FSTAGE_REW1\n",
        "\n",
        "\n",
        "\n",
        "print(\"Will load Julia and Julia code now....wait\")\n",
        "import julia\n",
        "jl = julia.Julia(compiled_modules=False)\n",
        "from julia import Main\n",
        "x = Main.include(\"juliacodeV4.jl\")\n",
        "Main.V=V\n",
        "Main.A=A\n",
        "Main.DESTC=DESTC\n",
        "Main.PROBC=PROBC\n",
        "Main.REWV=REWV\n",
        "Main.CAPV=CAPV\n",
        "Main.DURV=DURV\n",
        "Main.PROBOD=PROBOD\n",
        "Main.REWOD=REWOD\n",
        "Main.PRICEOD = PRICEOD\n",
        "Main.NUMBERNODES = NUMBERNODES\n",
        "print(\"Julia code loaded\")\n",
        "\n",
        "\n",
        "#run DRL Variant 2 Exact\n",
        "start_time = time()\n",
        "SOL_FSTAGE_REW2E=SOL_FSTAGE_REW2H\n",
        "#SOL_FSTAGE_REW2E,SOLVALUE_REW2E =run_DRL(DESTC,CAPV,REWV,'DRL_REW2E',NUMBERNODES,scenario,epsilon,learning_rate,MAXITER,LAST_SCENARIO_TO_TRAIN)\n",
        "TIME_DRL_REW2E= time()-start_time\n",
        "\n",
        "\n",
        "\n",
        "#Initiate simulation comparing best V value function with reoptimization\n",
        "\n",
        "print(\"Simulating Value Funtion with REWARD VARIANT 1\")\n",
        "bestZ = SOL_FSTAGE_REW1\n",
        "print(bestZ)\n",
        "bestZ = [int(round(x)) for x in bestZ]\n",
        "firststage = [0 for _ in range(len(DESTC))]\n",
        "for i in range(len(DESTC)):\n",
        "  firststage[bestZ[i]-1]= DESTC[i]\n",
        "\n",
        "episode =FIRST_SCENARIO_TO_SIMULATE\n",
        "RESULT_SIMU_REW1 = 0\n",
        "while episode < LAST_SCENARIO_TO_SIMULATE:\n",
        "  #print(episode,\" \")\n",
        "  for _ in range(4):\n",
        "    if episode%100==0:\n",
        "      print(episode,\" ,\")\n",
        "    #calculate reward 1 for this scenario\n",
        "    RESULT_SIMU_REW1+=calculate_reward1(A,DURV,REWV,CAPV,DESTC,firststage,episode)\n",
        "    episode+=1\n",
        "\n",
        "\n",
        "print(\"Simulating Value Funtion  for REWARD VARIANT 1\", RESULT_SIMU_REW1)\n",
        "input()\n",
        "\n",
        "print(\"Simulating Value Funtion with random solution with REWARD VARIANT 1\")\n",
        "\n",
        "zetatest = np.random.permutation(list(range(1,len(DESTC)+1)))\n",
        "#print(zetatest)\n",
        "zetatest = [int(round(x)) for x in zetatest]\n",
        "firststage = [0 for _ in range(len(DESTC))]\n",
        "for i in range(len(DESTC)):\n",
        "  firststage[zetatest[i]-1]= DESTC[i]\n",
        "episode =FIRST_SCENARIO_TO_SIMULATE\n",
        "RESULT_SIMU_REW1_RAND = 0\n",
        "while episode < LAST_SCENARIO_TO_SIMULATE:\n",
        "  #print(episode,\" \")\n",
        "  for _ in range(4):\n",
        "    if episode%100==0:\n",
        "      print(episode,\" ,\")\n",
        "    #calculate reward 1 for this scenario\n",
        "    RESULT_SIMU_REW1_RAND+=calculate_reward1(A,DURV,REWV,CAPV,DESTC,firststage,episode)\n",
        "    episode +=1\n",
        "\n",
        "print(\"Simulating Value Funtion  with random solution REWARD VARIANT 1\", RESULT_SIMU_REW1_RAND)\n",
        "##input()\n",
        "\n",
        "\n",
        "##print(\"Simulating Value Funtion with Second random solution with REWARD VARIANT 1\")\n",
        "\n",
        "#zetatest = np.random.permutation(list(range(1,len(DESTC)+1)))\n",
        "#print(zetatest)\n",
        "#zetatest = [int(round(x)) for x in zetatest]\n",
        "#firststage = [0 for _ in range(len(DESTC))]\n",
        "#for i in range(len(DESTC)):\n",
        "#  firststage[zetatest[i]-1]= DESTC[i]\n",
        "#episode =FIRST_SCENARIO_TO_SIMULATE\n",
        "#episodetotalreturn = 0\n",
        "#while episode < LAST_SCENARIO_TO_SIMULATE:\n",
        "#  #print(episode,\" \")\n",
        "#  for _ in range(4):\n",
        "#    if episode%100==0:\n",
        "#      print(episode,\" ,\")\n",
        "#    #calculate reward 1 for this scenario\n",
        "#    episodetotalreturn+=calculate_reward1(A,DURV,REWV,CAPV,DESTC,firststage,episode)\n",
        "#    episode +=1\n",
        "#print(\"Simulating Value Funtion  with Second random solution REWARD VARIANT 1\", episodetotalreturn)\n",
        "##input()\n",
        "\n",
        "\n",
        "\n",
        "#print(\"Simulation using result from best Value Function with REWARD VARIANT 2 EXACT\")\n",
        "#bestZ = SOL_FSTAGE_REW2E\n",
        "#print(bestZ)\n",
        "#firststage = [0 for _ in range(len(DESTC))]\n",
        "#for i in range(len(DESTC)):\n",
        "#  firststage[bestZ[i]-1]= DESTC[i]\n",
        "#episode =FIRST_SCENARIO_TO_SIMULATE\n",
        "#RESULT_SIMU_REW2E = 0\n",
        "#TOTAL_OD_DECISIONS = 0\n",
        "#TOTAL_OD_ALLOCATIONS = 0\n",
        "#while episode < LAST_SCENARIO_TO_SIMULATE:\n",
        "#  #print(episode,\" \")\n",
        "#    for _ in range(4):\n",
        "#      if episode%100==0:\n",
        "#        print(episode,\" ,\")\n",
        "#      #calculate reward 2 exact for this scenario\n",
        "#      Main.scenario = scenario[episode]\n",
        "#      Main.firststage = firststage\n",
        "#      RES1,RES3,RES2= jl.eval(\"rewardvariant2(V,A,REWV,PRICEOD,DESTC,scenario,firststage)\")\n",
        "#      RESULT_SIMU_REW2E+= RES2\n",
        "#      TOTAL_OD_DECISIONS += sum(scenario[episode][len(DESTC):2*len(DESTC)])\n",
        "#      TOTAL_OD_ALLOCATIONS += RES1\n",
        "#      episode +=1\n",
        "\n",
        "#print(\"Simulation using result from best Value Function with REWARD VARIANT 2 EXACT \", RESULT_SIMU_REW2E,\" ,\",TOTAL_OD_ALLOCATIONS,\" ,\",TOTAL_OD_DECISIONS)\n",
        "##input()\n",
        "\n",
        "#print(\"Simulating Value Funtion with REWARD VARIANT 2 HEUR\")\n",
        "#bestZ = SOL_FSTAGE_REW2H\n",
        "#print(bestZ)\n",
        "#firststage = [0 for _ in range(len(DESTC))]\n",
        "#for i in range(len(DESTC)):\n",
        "#  firststage[bestZ[i]-1]= DESTC[i]\n",
        "\n",
        "#episode =FIRST_SCENARIO_TO_SIMULATE\n",
        "#RESULT_SIMU_REW2H = 0\n",
        "#while episode < LAST_SCENARIO_TO_SIMULATE:\n",
        "#  #print(episode,\" \")\n",
        "#  for _ in range(4):\n",
        "#    if episode%10==0:\n",
        "#      print(episode,\" ,\")\n",
        "#    #calculate reward 2 heur for this scenario\n",
        "#    RESULT_SIMU_REW2H+=calculate_reward2heuristic(A,DURV,REWV,CAPV,DESTC,firststage,scenario,episode)\n",
        "#    episode +=1\n",
        "#print(\"Simulation using result from best Value Function with REWARD VARIANT 2 HEUR \", RESULT_SIMU_REW2H)\n",
        "##input()\n",
        "\n",
        "\n",
        "\n",
        "#print(\"Simulating Reoptimization: considers Variant 1 type reward\")\n",
        "#episode =FIRST_SCENARIO_TO_SIMULATE\n",
        "#RESULT_SIMU_REOPT = 0\n",
        "#while episode < LAST_SCENARIO_TO_SIMULATE:\n",
        "#  #print(episode,\" \")\n",
        "#  episodecost = 0\n",
        "#  for _ in range(4):\n",
        "#    if episode%100==0:\n",
        "#      print(episode,\" ,\")\n",
        "#    Main.scenario = scenario[episode]\n",
        "#    RESULT_SIMU_REOPT += jl.eval(\"reoptimization(V,A,REWV,PRICEOD,DESTC,scenario)\")\n",
        "#    episode +=1\n",
        "#  RESULT_SIMU_REOPT+=episodecost\n",
        "#  print(episode,\" : \",RESULT_SIMU_REOPT)\n",
        "#print(\"Simulation using result from Reoptimization \", RESULT_SIMU_REOPT)\n",
        "##input()\n",
        "\n",
        "data = [' ',inst_id,ALGO,MAXITER,epsilon,learning_rate,NUMBERNODES,epoch,batch,LAST_SCENARIO_TO_TRAIN,\n",
        "SOLVALUE_REW1,TIME_DRL_REW1,SOLVALUE_REW2E,TIME_DRL_REW2E, SOLVALUE_REW2H,TIME_DRL_REW2H,SOLVALUE_DRO,TIME_DRO,RESULT_SIMU_REW1,RESULT_SIMU_REW1_RAND,RESULT_SIMU_REW2E,RESULT_SIMU_REW2H,RESULT_SIMU_DRO,RESULT_SIMU_REOPT, TOTAL_OD_DECISIONS,TOTAL_OD_ALLOCATIONS]\n",
        "\n",
        "writer.writerow(data)\n",
        "f.close()\n",
        "\n"
      ]
    }
  ]
}